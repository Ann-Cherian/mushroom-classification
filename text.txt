# Install dependencies

!pip install pandas scikit-learn seaborn joblib matplotlib

# Import libraries

import joblib
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz
from tkinter import *

# Data exploration

## Dataset acquisition

data = pd.read_csv("mushrooms.csv")
pd.set_option('display.max_columns', None)

## Exploratory data analysis

### Information of dataset

data.info()

### First five rows in dataset

data.head()

### Last five rows in dataset

data.tail()

### Null values in dataset

data.isnull().sum()

### Dataset dimensions

print("Number of features:", data.shape[1])
print("Number of values:", data.shape[0])

### Statistics of datatset

data.describe()

# Data Preprocessing

## Categorical Encoding

### Change features type to category

data = data.astype('category')
data.dtypes

### Data encoding

for column in data.columns:
    data[column] = LabelEncoder().fit_transform(data[column])

data.head()

## Train-Test Split

### Principal component analysis

X = data.drop('class', axis=1)
y = data['class']
pca = PCA(n_components = 7)
pca_fit = pca.fit_transform(X)

### Split dataset into 80% training and 20% testing

X_train, X_test, y_train, y_test = train_test_split(pca_fit, y, test_size = 0.20, random_state = 42)

# Classification models

models_names = ['Logistic Regression', 'K Neighbors', 'Support Vectore Machine', 'Decision Tree', 'Random Foreest', 'Gradient Boosting']
models_accuracies = []
models_precisions = []
models_recalls = []
models_f1_scores = []
models_supports = []

## 1. Logistic Regression

logistic_regression = LogisticRegression()
logistic_regression.fit(X_train, y_train)
y_pred_logistic_regression = logistic_regression.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_logistic_regression)
models_accuracies.append(accuracy)
print("Accuracy:", accuracy)

### 1.1 Confusion Matrix

cm = confusion_matrix(y_test, y_pred_logistic_regression)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Edible", "Poisonous"])
disp.plot()

### 1.2 Classification Report

cr = classification_report(y_test, y_pred_logistic_regression, target_names=["Edible", "Poisonous"], output_dict=True)
models_precisions.append(cr.get("weighted avg").get("precision"))
models_recalls.append(cr.get("weighted avg").get("recall"))
models_f1_scores.append(cr.get("weighted avg").get("f1-score"))
models_supports.append(cr.get("weighted avg").get("support"))
print(classification_report(y_test, y_pred_logistic_regression, target_names=["Edible", "Poisonous"]))

### 1.3 ROC curve

fpr, tpr, thresholds = roc_curve(y_test, y_pred_logistic_regression)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

### 1.4 Dataset graph of actual vs predicted values

sns.scatterplot(x=y_test, y=y_pred_logistic_regression, hue=y_pred_logistic_regression, palette='viridis', s=100, alpha=0.7)
plt.title('Actual vs Predicted Values')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend(title='Predicted', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

## 2. K Nearest Neighbors

k_nearest_neighbors = KNeighborsClassifier()
k_nearest_neighbors.fit(X_train, y_train)
y_pred_k_nearest_neighbors = k_nearest_neighbors.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_k_nearest_neighbors)
models_accuracies.append(accuracy)
print("Accuracy:", accuracy)

### 2.1 Confusion Matrix

cm = confusion_matrix(y_test, y_pred_k_nearest_neighbors)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Edible", "Poisonous"])
disp.plot()

### 2.2 Classification Report

cr = classification_report(y_test, y_pred_k_nearest_neighbors, target_names=["Edible", "Poisonous"], output_dict=True)
models_precisions.append(cr.get("weighted avg").get("precision"))
models_recalls.append(cr.get("weighted avg").get("recall"))
models_f1_scores.append(cr.get("weighted avg").get("f1-score"))
models_supports.append(cr.get("weighted avg").get("support"))
print(classification_report(y_test, y_pred_k_nearest_neighbors, target_names=["Edible", "Poisonous"]))

### 2.3 ROC curve

fpr, tpr, thresholds = roc_curve(y_test, y_pred_k_nearest_neighbors)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

## 3. Support Vector Machine

support_vector_machine = SVC()
support_vector_machine.fit(X_train, y_train)
y_pred_support_vector_machine = support_vector_machine.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_support_vector_machine)
models_accuracies.append(accuracy)
print("Accuracy:", accuracy)

### 3.1 Confusion Matrix

cm = confusion_matrix(y_test, y_pred_support_vector_machine)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Edible", "Poisonous"])
disp.plot()

### 3.2 Classification Report

cr = classification_report(y_test, y_pred_support_vector_machine, target_names=["Edible", "Poisonous"], output_dict=True)
models_precisions.append(cr.get("weighted avg").get("precision"))
models_recalls.append(cr.get("weighted avg").get("recall"))
models_f1_scores.append(cr.get("weighted avg").get("f1-score"))
models_supports.append(cr.get("weighted avg").get("support"))
print(classification_report(y_test, y_pred_support_vector_machine, target_names=["Edible", "Poisonous"]))

### 3.3 ROC curve

fpr, tpr, thresholds = roc_curve(y_test, y_pred_support_vector_machine)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

## 4. Decision Tree

decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)
y_pred_decision_tree = decision_tree.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_decision_tree)
models_accuracies.append(accuracy)
print("Accuracy:", accuracy)

### 4.1 Confusion Matrix

cm = confusion_matrix(y_test, y_pred_decision_tree)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Edible", "Poisonous"])
disp.plot()

### 4.2 Classification Report

cr = classification_report(y_test, y_pred_decision_tree, target_names=["Edible", "Poisonous"], output_dict=True)
models_precisions.append(cr.get("weighted avg").get("precision"))
models_recalls.append(cr.get("weighted avg").get("recall"))
models_f1_scores.append(cr.get("weighted avg").get("f1-score"))
models_supports.append(cr.get("weighted avg").get("support"))
print(classification_report(y_test, y_pred_decision_tree, target_names=["Edible", "Poisonous"]))

### 4.3 ROC curve

fpr, tpr, thresholds = roc_curve(y_test, y_pred_decision_tree)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

## 5. Random Forest

random_forest = RandomForestClassifier()
random_forest.fit(X_train, y_train)
y_pred_random_forest = random_forest.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_random_forest)
models_accuracies.append(accuracy)
print("Accuracy:", accuracy)

### 5.1 Confusion Matrix

cm = confusion_matrix(y_test, y_pred_random_forest)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Edible", "Poisonous"])
disp.plot()

### 5.2 Classification Report

cr = classification_report(y_test, y_pred_random_forest, target_names=["Edible", "Poisonous"], output_dict=True)
models_precisions.append(cr.get("weighted avg").get("precision"))
models_recalls.append(cr.get("weighted avg").get("recall"))
models_f1_scores.append(cr.get("weighted avg").get("f1-score"))
models_supports.append(cr.get("weighted avg").get("support"))
print(classification_report(y_test, y_pred_random_forest, target_names=["Edible", "Poisonous"]))

### 5.3 ROC curve

fpr, tpr, thresholds = roc_curve(y_test, y_pred_random_forest)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

## 6. Gradient Boosting

gradient_boosting = GradientBoostingClassifier()
gradient_boosting.fit(X_train, y_train)
y_pred_gradient_boosting = gradient_boosting.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_gradient_boosting)
models_accuracies.append(accuracy)
print("Accuracy:", accuracy)

### 6.1 Confusion Matrix

cm = confusion_matrix(y_test, y_pred_gradient_boosting)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Edible", "Poisonous"])
disp.plot()

### 6.2 Classification Report

cr = classification_report(y_test, y_pred_gradient_boosting, target_names=["Edible", "Poisonous"], output_dict=True)
models_precisions.append(cr.get("weighted avg").get("precision"))
models_recalls.append(cr.get("weighted avg").get("recall"))
models_f1_scores.append(cr.get("weighted avg").get("f1-score"))
models_supports.append(cr.get("weighted avg").get("support"))
print(classification_report(y_test, y_pred_gradient_boosting, target_names=["Edible", "Poisonous"]))

### 6.3 ROC curve

fpr, tpr, thresholds = roc_curve(y_test, y_pred_gradient_boosting)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

# Comparing models

final_data = pd.DataFrame({"Models": models_names, "Accuracy": models_accuracies, "Avg Precision": models_precisions, "Avg Recall": models_recalls, "Avg F1 Score": models_f1_scores, "Avg Support": models_supports})
final_data

## Comparison graphs

### Accuracy

g = sns.barplot(x=final_data['Models'],y=final_data['Accuracy'])
g.set_xticklabels(g.get_xticklabels(), rotation=30)

### Precision

g = sns.barplot(x=final_data['Models'],y=final_data['Avg Precision'])
g.set_xticklabels(g.get_xticklabels(), rotation=30)

### Recall

g = sns.barplot(x=final_data['Models'],y=final_data['Avg Recall'])
g.set_xticklabels(g.get_xticklabels(), rotation=30)

### F1 Score

g = sns.barplot(x=final_data['Models'],y=final_data['Avg F1 Score'])
g.set_xticklabels(g.get_xticklabels(), rotation=30)

### Support

g = sns.barplot(x=final_data['Models'],y=final_data['Avg Support'])
g.set_xticklabels(g.get_xticklabels(), rotation=30)

# Prediction app

## Save model

rf_model = RandomForestClassifier()
rf_model.fit(pca_fit,y)
joblib.dump(rf_model,"Mushroom_prediction")

## User Interface

def show_entry_fields():
    p1=int(e1.get())
    p2=int(e2.get())
    p3=int(e3.get())
    p4=int(e4.get())
    p5=int(e5.get())
    p6=int(e6.get())
    p7=int(e7.get())
    p8=int(e8.get())
    p9=int(e9.get()) 
    p10=int(e10.get())
    p11=int(e11.get())
    
    p12=int(e12.get())
    p13=int(e13.get())
    p14=int(e14.get())
    p15=int(e15.get())
    p16=int(e16.get())
    p17=int(e17.get())
    p18=int(e18.get())
    p19=int(e19.get())
    p20=int(e20.get())
    p21=int(e21.get())
    p22=int(e22.get())
    
    model = joblib.load('Mushroom_prediction')
    result=model.predict(pca.transform([[p1,p2,p3,p4,p5,p6,
                           p7,p8,p9,p10,p11,p12,p13,p14,p15,
                            p16,p17,p18,p19,p20,p21,p22]]))
    
    if result[0] == 0:
        Label(master, text="Edible").grid(row=31)
    else:
        Label(master, text="Poisonous").grid(row=31)
    
    
master = Tk()
master.title("Mushroom Classification Using Machine Learning")


label = Label(master, text = "Mushroom Classification Using Machine Learning"
                          , bg = "black", fg = "white"). \
                               grid(row=0,columnspan=2)


Label(master,text="cap-shape :(cap-shape: bell=0,conical=1,convex=5,flat=2, knobbed=3,sunken=4)").grid(row=1)
Label(master, text="cap-surface:(fibrous=0,grooves=1,scaly=3,smooth=2)").grid(row=2)
Label(master, text="cap-color:(brown=4,buff=0,cinnamon=1,gray=3,green=r, \
pink=5,purple=6,red=2,white=7,yellow=8)").grid(row=3)
Label(master, text="bruises:(bruises=1,no=0)").grid(row=4)
Label(master, text="odor:(almond=0,anise=3,creosote=1,fishy=8,foul=2,\
musty=4,none=5,pungent=6,spicy=7 \
)").grid(row=5)
Label(master, text="gill-attachment:(attached=0,descending=1,free=2,notched=3)").grid(row=6)
Label(master, text="gill-spacing:(close=0,crowded=2,distant=1 \
)").grid(row=7)
Label(master, text="gill-size:(road=0,narrow=1)").grid(row=8)
Label(master, text="gill-color:(black=4,brown=5,buff=0,chocolate=3,gray=2,green=8,orange=6,pink=7,purple=9,red=1,white=10,yellow=11)").grid(row=9)
Label(master, text="stalk-shape:(enlarging=0,tapering=1)").grid(row=10)
Label(master,text="stalk-root:( bulbous=0,club=1,cup=5,equal=2,rhizomorphs=4, \
rooted=3,missing=6)").grid(row=11)

Label(master,text="stalk-surface-above-ring:(fibrous=0,scaly=3,silky=1,smooth=2)").grid(row=12)
Label(master,text="stalk-surface-below-ring:(fibrous=0,scaly=3,silky=1,smooth=2 \
)").grid(row=13)
Label(master,text="stalk-color-above-ring:(brown=4,buff=0,cinnamon=1,gray=3, \
orange=5,pink=6,red=2,white=7,yellow=8)").grid(row=14)
Label(master,text="stalk-color-below-ring:(brown=4,buff=0,cinnamon=1,gray=3, \
orange=5,pink=6,red=2,white=7,yellow=8)").grid(row=15)
Label(master,text="veil-type:(partial=0,universal=1)").grid(row=16)
Label(master,text="veil-color:(brown=0,orange=1,white=2,yellow=3)").grid(row=17)
Label(master,text="ring-number:(none=0,one=1,two=2)").grid(row=18)
Label(master,text="ring-type:(cobwebby=0,evanescent=1,flaring=2,large=3,\
none=4,pendant=5,sheathing=6,zone=7)").grid(row=19)
Label(master,text="spore-print-color:(black=2,brown=3,buff=0,chocolate=1, \
green=5,orange=4,purple=6,white=7,yellow=8 \
)").grid(row=20)

Label(master,text="population:(abundant=0,clustered=1,numerous=2,scattered=3, \
# several=4,solitary=5)").grid(row=21)
Label(master,text="habitat:(grasses=1,leaves=2,meadows=3,paths=4,urban=5,\
# waste=6,woods=0)").grid(row=22)

e1 = Entry(master)
e2 = Entry(master)
e3 = Entry(master)
e4 = Entry(master)
e5 = Entry(master)
e6 = Entry(master)
e7 = Entry(master)
e8 = Entry(master)
e9 = Entry(master)
e10 = Entry(master)
e11 = Entry(master)

e12 = Entry(master)
e13 = Entry(master)
e14 = Entry(master)
e15 = Entry(master)
e16 = Entry(master)
e17 = Entry(master)
e18 = Entry(master)
e19 = Entry(master)
e20 = Entry(master)
e21 = Entry(master)
e22 = Entry(master)



e1.grid(row=1, column=1)
e2.grid(row=2, column=1)
e3.grid(row=3, column=1)
e4.grid(row=4, column=1)
e5.grid(row=5, column=1)
e6.grid(row=6, column=1)
e7.grid(row=7, column=1)
e8.grid(row=8, column=1)
e9.grid(row=9, column=1)
e10.grid(row=10,column=1)
e11.grid(row=11,column=1)

e12.grid(row=12,column=1)
e13.grid(row=13,column=1)
e14.grid(row=14,column=1)
e15.grid(row=15,column=1)
e16.grid(row=16,column=1)
e17.grid(row=17,column=1)
e18.grid(row=18,column=1)
e19.grid(row=19,column=1)
e20.grid(row=20,column=1)
e21.grid(row=21,column=1)
e22.grid(row=22,column=1)

Button(master, text='Predict', command=show_entry_fields).grid()

mainloop()